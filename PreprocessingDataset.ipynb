{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNgitgfW5L7guY9OffYRoUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrinaOltean14/Research/blob/main/PreprocessingDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP7NbgRdxZDS",
        "outputId": "d7470faa-ec51-4224-d644-2ceef4afbb7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.18.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.18.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.18.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.18.0-py2.py3-none-any.whl (317 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.5/317.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: typeguard, smmap, setproctitle, sentry-sdk, docker-pycreds, tensorflow-addons, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.18.0 setproctitle-1.3.3 smmap-5.0.1 tensorflow-addons-0.23.0 typeguard-2.13.3 wandb-0.18.6\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons wandb pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOAeIm9HzIMw",
        "outputId": "65a29b06-346d-4724-a6cb-d1c75fcafac7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "rzwMdvl1zOc_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KYQaK_gzSM_",
        "outputId": "184cec84-d74d-4541-830a-3c7ace61ccf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import os\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"semart-multi-task\", name=\"ResNet18-multi-task-TF\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "nvAZi-qpzm72",
        "outputId": "c8a57f4a-0ca5-41a9-9134-9c96007d974e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33molteanirina1\u001b[0m (\u001b[33molteanirina1-babes-bolyai-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241112_191647-ig80rouy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/olteanirina1-babes-bolyai-university/semart-multi-task/runs/ig80rouy' target=\"_blank\">ResNet18-multi-task-TF</a></strong> to <a href='https://wandb.ai/olteanirina1-babes-bolyai-university/semart-multi-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/olteanirina1-babes-bolyai-university/semart-multi-task' target=\"_blank\">https://wandb.ai/olteanirina1-babes-bolyai-university/semart-multi-task</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/olteanirina1-babes-bolyai-university/semart-multi-task/runs/ig80rouy' target=\"_blank\">https://wandb.ai/olteanirina1-babes-bolyai-university/semart-multi-task/runs/ig80rouy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/olteanirina1-babes-bolyai-university/semart-multi-task/runs/ig80rouy?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ba0f74c3f40>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr5AKk4Wzy6e",
        "outputId": "3f85c4fc-7046-41bf-894e-1044fccc78b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the path to your Images folder\n",
        "images_folder_path = '/content/drive/MyDrive/SemArt/Images'\n",
        "\n",
        "# Count the number of files in the folder\n",
        "image_count = len([f for f in os.listdir(images_folder_path) if f.endswith('.jpg')])\n",
        "\n",
        "print(f\"Total number of images in the folder: {image_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksgpg6Ehz9mG",
        "outputId": "ff873796-1714-48eb-9e3d-66b512928b22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in the folder: 21424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd # Used for data cleaning, exploration, and preprocessing\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array # functions are used to load images from disk and convert them into NumPy arrays\n",
        "from sklearn.preprocessing import LabelEncoder # categorical variables into numerical labels"
      ],
      "metadata": {
        "id": "lk-IiGDz05H7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "images_folder_path = '/content/drive/MyDrive/SemArt/Images'\n",
        "train_csv_path = '/content/drive/MyDrive/SemArt/semart_train.csv'\n",
        "val_csv_path = '/content/drive/MyDrive/SemArt/semart_val.csv'\n",
        "test_csv_path = '/content/drive/MyDrive/SemArt/semart_test.csv'"
      ],
      "metadata": {
        "id": "MuLgp31y1VRf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load csv. Prepare columns for image paths, school and date\n",
        "def load_csv(csv_path):\n",
        "    df = pd.read_csv(csv_path, sep='\\t', encoding='ISO-8859-1')\n",
        "    # Create full image path\n",
        "    df['image_path'] = df['IMAGE_FILE'].apply(lambda x: os.path.join(images_folder_path, x))\n",
        "    return df[['image_path', 'SCHOOL', 'TYPE']]\n",
        "\n",
        "train_df = load_csv(train_csv_path)\n",
        "val_df = load_csv(val_csv_path)\n",
        "test_df = load_csv(test_csv_path)"
      ],
      "metadata": {
        "id": "fgrMwGc51dP3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vizualize data frames\n",
        "# View the first 10 rows of the training DataFrame\n",
        "print(\"Train Dataframe - Top 15:\")\n",
        "print(train_df.head(15))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U-RMSVj20nG",
        "outputId": "047272f7-ab4e-4db2-f672-6c379fe78a84"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataframe - Top 15:\n",
            "                                           image_path         SCHOOL  \\\n",
            "0   /content/drive/MyDrive/SemArt/Images/19873-1da...         German   \n",
            "1   /content/drive/MyDrive/SemArt/Images/18759-gua...        Italian   \n",
            "2   /content/drive/MyDrive/SemArt/Images/04589-tem...        Italian   \n",
            "3   /content/drive/MyDrive/SemArt/Images/15104-mag...  Netherlandish   \n",
            "4   /content/drive/MyDrive/SemArt/Images/36582-pao...          Dutch   \n",
            "5   /content/drive/MyDrive/SemArt/Images/00930-30c...        Italian   \n",
            "6   /content/drive/MyDrive/SemArt/Images/24485-01v...        Italian   \n",
            "7   /content/drive/MyDrive/SemArt/Images/18424-210...        Spanish   \n",
            "8   /content/drive/MyDrive/SemArt/Images/21949-4la...        Italian   \n",
            "9   /content/drive/MyDrive/SemArt/Images/03093-cal...        Flemish   \n",
            "10  /content/drive/MyDrive/SemArt/Images/20320-mou...        Flemish   \n",
            "11  /content/drive/MyDrive/SemArt/Images/08705-pie...         French   \n",
            "12  /content/drive/MyDrive/SemArt/Images/07640-des...        Spanish   \n",
            "13  /content/drive/MyDrive/SemArt/Images/39738-04o...        Italian   \n",
            "14  /content/drive/MyDrive/SemArt/Images/29467-can...          Dutch   \n",
            "\n",
            "            TYPE  \n",
            "0      religious  \n",
            "1      landscape  \n",
            "2      religious  \n",
            "3      religious  \n",
            "4          other  \n",
            "5      religious  \n",
            "6      religious  \n",
            "7       portrait  \n",
            "8      religious  \n",
            "9      religious  \n",
            "10     landscape  \n",
            "11     religious  \n",
            "12     religious  \n",
            "13  mythological  \n",
            "14     landscape  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to encode SCHOOL and TYPE into numerical labels\n",
        "school_encoder = LabelEncoder()\n",
        "type_encoder = LabelEncoder()\n",
        "\n",
        "# Fit encoders on the train data (only train data to prevent data leakage)\n",
        "train_df['SCHOOL'] = school_encoder.fit_transform(train_df['SCHOOL'])\n",
        "train_df['TYPE'] = type_encoder.fit_transform(train_df['TYPE'])\n",
        "\n",
        "# Apply encoders to validation and test splits\n",
        "val_df['SCHOOL'] = school_encoder.transform(val_df['SCHOOL'])\n",
        "val_df['TYPE'] = type_encoder.transform(val_df['TYPE'])\n",
        "test_df['SCHOOL'] = school_encoder.transform(test_df['SCHOOL'])\n",
        "test_df['TYPE'] = type_encoder.transform(test_df['TYPE'])\n"
      ],
      "metadata": {
        "id": "5d6xaSLX30WH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)  # Image size for ResNet model\n",
        "\n",
        "def process_image(file_path):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3) # output -> tensor representing the image\n",
        "    img = tf.image.resize(img, IMG_SIZE) # ensures that all images have the same dimensions\n",
        "    img = tf.keras.applications.resnet.preprocess_input(img) # specific preprocessing steps to the image, tailored for ResNet models\n",
        "    return img\n",
        "\n",
        "def process_labels(school, type_):\n",
        "    school_label = tf.convert_to_tensor(school, dtype=tf.int32)\n",
        "    type_label = tf.convert_to_tensor(type_, dtype=tf.int32)\n",
        "    return school_label, type_label\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "l3bs7-WJBhJt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}